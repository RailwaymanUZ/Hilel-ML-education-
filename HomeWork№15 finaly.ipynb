{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:50:29.627476100Z",
     "start_time": "2023-10-30T09:50:23.535941100Z"
    }
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from huggingface_sb3 import load_from_hub\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def see_game(model):\n",
    "    \n",
    "    \"\"\" Функція, що показує нам як грає модель\"\"\"\n",
    "    \n",
    "    # Создание среды\n",
    "    env = make_vec_env(\"LunarLander-v2\", n_envs=1, seed=42)\n",
    "    \n",
    "    # Оценка модели\n",
    "    print(\"Оценка модели\")\n",
    "    mean_reward, std_reward = evaluate_policy(\n",
    "        model,\n",
    "        env,\n",
    "        n_eval_episodes=20,\n",
    "        deterministic=True,\n",
    "    )\n",
    "    print(f\"Средняя награда = {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "    \n",
    "    # Начало новой эпизода\n",
    "    obs = env.reset()\n",
    "    try:\n",
    "        while True:\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            obs, rewards, dones, info = env.step(action)\n",
    "            env.render(mode='human')  # Рендеринг окружения\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:48:13.510331500Z",
     "start_time": "2023-10-30T09:48:13.495802200Z"
    }
   },
   "id": "311a9b449d12cdc9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Спробуємо навчити модель та побачити що вона буде робити, коли буде не донавченною"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14aa8030b1ee539b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 91.2     |\n",
      "|    ep_rew_mean     | -183     |\n",
      "| time/              |          |\n",
      "|    fps             | 7805     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 91.9         |\n",
      "|    ep_rew_mean          | -140         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4760         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043834154 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.00188      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.12e+03     |\n",
      "|    n_updates            | 4            |\n",
      "|    policy_gradient_loss | -0.00477     |\n",
      "|    value_loss           | 5.07e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98.5        |\n",
      "|    ep_rew_mean          | -140        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4152        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006420245 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -0.0106     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 845         |\n",
      "|    n_updates            | 8           |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    value_loss           | 2.44e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 107          |\n",
      "|    ep_rew_mean          | -123         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3812         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061184084 |\n",
      "|    clip_fraction        | 0.0321       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | -0.000926    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 615          |\n",
      "|    n_updates            | 12           |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 99.3         |\n",
      "|    ep_rew_mean          | -112         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3608         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065660398 |\n",
      "|    clip_fraction        | 0.063        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 3.41e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 721          |\n",
      "|    n_updates            | 16           |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    value_loss           | 1.05e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 93.8        |\n",
      "|    ep_rew_mean          | -90.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3541        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009485974 |\n",
      "|    clip_fraction        | 0.0791      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -0.00472    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 471         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    value_loss           | 586         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-51.62 +/- 146.23\n",
      "Episode length: 494.30 +/- 141.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 494         |\n",
      "|    mean_reward          | -51.6       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008921141 |\n",
      "|    clip_fraction        | 0.0843      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.00199     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 24          |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    value_loss           | 387         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 97.7     |\n",
      "|    ep_rew_mean     | -79.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 3084     |\n",
      "|    iterations      | 7        |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 114688   |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env_id = \"LunarLander-v2\"\n",
    "n_envs = 16\n",
    "env = make_vec_env(env_id, n_envs=n_envs, seed=42)\n",
    "\n",
    "# Create the evaluation envs\n",
    "eval_envs = make_vec_env(env_id, n_envs=5, seed=42)\n",
    "\n",
    "# Adjust evaluation interval depending on the number of envs\n",
    "eval_freq = int(1e5)\n",
    "eval_freq = max(eval_freq // n_envs, 1)\n",
    "\n",
    "# Create evaluation callback to save best model\n",
    "# and monitor agent performance\n",
    "eval_callback = EvalCallback(\n",
    "    eval_envs,\n",
    "    best_model_save_path=\"./logs/\",\n",
    "    eval_freq=eval_freq,\n",
    "    n_eval_episodes=10,\n",
    ")\n",
    "\n",
    "# Instantiate the agent\n",
    "# Hyperparameters from https://github.com/DLR-RM/rl-baselines3-zoo\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    n_steps=1024,\n",
    "    batch_size=64,\n",
    "    gae_lambda=0.98,\n",
    "    gamma=0.999,\n",
    "    n_epochs=4,\n",
    "    ent_coef=0.01,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Train the agent (you can kill it before using ctrl+c)\n",
    "env.reset()\n",
    "try:\n",
    "    model.learn(total_timesteps=100000, callback=eval_callback)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "# Save\n",
    "model.save('logs/model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:49:01.171482500Z",
     "start_time": "2023-10-30T09:48:20.862360200Z"
    }
   },
   "id": "c6ea3dcb080e9ece"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Подивимось як граэ недонавченна наша модель"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23f91f2ee1d37df9"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "my_model = model.load('logs/model.zip')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:49:05.303380900Z",
     "start_time": "2023-10-30T09:49:05.280937600Z"
    }
   },
   "id": "ee60fd6edbe2f3fe"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:166: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at least 16 arguments, got 15\n",
      "  warnings.warn(\n",
      "C:\\Users\\lemes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:166: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at least 16 arguments, got 15\n",
      "  warnings.warn(\n",
      "C:\\Users\\lemes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:95: UserWarning: You loaded a model that was trained using OpenAI Gym. We strongly recommend transitioning to Gymnasium by saving that model again.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "checkpoint = load_from_hub(\"araffin/ppo-LunarLander-v2\", \"ppo-LunarLander-v2.zip\")\n",
    "best_model = PPO.load(checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:49:06.834403500Z",
     "start_time": "2023-10-30T09:49:06.595851200Z"
    }
   },
   "id": "cb71841b1fbafb07"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка модели\n",
      "Средняя награда = -146.10 +/- 36.31\n"
     ]
    }
   ],
   "source": [
    "see_game(my_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:49:58.492318700Z",
     "start_time": "2023-10-30T09:49:14.543975600Z"
    }
   },
   "id": "da8793aeed052b26"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка модели\n",
      "Средняя награда = 281.78 +/- 17.37\n"
     ]
    }
   ],
   "source": [
    "see_game(best_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:45:37.834996400Z",
     "start_time": "2023-10-30T09:45:18.747076Z"
    }
   },
   "id": "244fb5df46366740"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
